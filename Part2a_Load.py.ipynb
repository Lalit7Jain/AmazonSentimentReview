{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Amazon Product Review Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import string\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We need a CSV file with two columns, one actual reviews and sentiment related (Positive, Negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_doc_list(folder_name):    \n",
    "    with open(folder_name+'\\\\'+ 'ReviewSentiment.csv') as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "        doc_list = []\n",
    "        sentiments = []\n",
    "        i = 0\n",
    "        for row in readCSV:\n",
    "            if i > 0:\n",
    "                doc_list.append(row[1])\n",
    "                sentiments.append(row[2])\n",
    "            i+=1\n",
    "        print ('Found %s documents'%(len(doc_list)))\n",
    "    return doc_list,sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Below code will clean the reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "def clean_text(text):\n",
    " \n",
    "    tokenizer = TweetTokenizer()\n",
    "    en_stop = get_stop_words('en')\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "    wordslist = []\n",
    "    tagslist = []\n",
    "\n",
    "    # clean and tokenize document string\n",
    "    raw = text.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "\n",
    "    # remove numbers\n",
    "    number_tokens = [re.sub(r'[\\d]', ' ', i) for i in stopped_tokens]\n",
    "    number_tokens = ' '.join(number_tokens).split()\n",
    "\n",
    "    # stem tokens\n",
    "    stemmed_tokens = [stemmer.stem(i) for i in number_tokens]\n",
    "\n",
    "    # remove empty\n",
    "    length_tokens = [i for i in stemmed_tokens if len(i) > 1]\n",
    "\n",
    "    # remove punctuations\n",
    "    punct_tokens  = [''.join(c for c in s if c not in string.punctuation) for s in length_tokens]\n",
    "\n",
    "\n",
    "    return punct_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ps', 'renam', 'label', 'data', 'tweetsnag', 'csv', 'simplis']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(\"\"\"PS: Here I renamed the labeled data as \"Tweets_NAg.csv\" for simplisity.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passing the directory of our file and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 documents\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "rev, senti = get_doc_list('C:\\\\Users\\\\lalit\\\\Dropbox\\\\NEU_Curriculum\\\\SEM5-Spring2017\\\\BigData-Analytics\\\\Final_Project\\\\SentimentAnalysis\\\\reviews\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Reviews\":rev,\"Sentiments\":senti})\n",
    "df = df[[u'Sentiments',u'Reviews']]\n",
    "df.loc[:,'Reviews'] = df.loc[:,'Reviews'].map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument,Doc2Vec\n",
    "\n",
    "## Traning and Testing\n",
    "TotalNum = int(df.size/2)\n",
    "\n",
    "TestNum = round(0.2 * TotalNum)\n",
    "TrainNum=TotalNum-TestNum\n",
    "\n",
    "documents = [TaggedDocument(list(df.loc[i,'Reviews']),[i]) for i in range(0,TotalNum)]\n",
    "\n",
    "Doc2VecTrainID = list(range(0,TotalNum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['cool', 'grandkid', 'five', 'seven', 'love', 'sometim', 'talk', 'littl', 'fast', 'understood'], tags=[1]),\n",
       " TaggedDocument(words=['instrument', 'might', 'greatest', 'thing', 'sinc', 'slice', 'bread', 'app', 'make', 'useless', 'lucki', 'might', 'recogn', 'password', 'router', 'tell', 'menus', 'dead', 'end', 'go', 'back', 'amazon', 'music', 'default', 'readi', 'yo', 'send', 'back', 'appl', 'devic', 'look', 'rate', 'app'], tags=[2]),\n",
       " TaggedDocument(words=['love', 'expect'], tags=[3]),\n",
       " TaggedDocument(words=['echo', 'awesom', 'cant', 'wait', 'get', 'connect', 'devic', 'light', 'light', 'thermostat', 'etc', '', 'thing', 'great', 'use', 'time', 'lot', 'fun', 'actual', 'quit', 'surpris', 'well', 'take', 'command', 'answer', 'question', 'expect', 'understand', 'can', 'even', 'alexa', 'start', 'car', 'now', 'note', 'think', 'manufactur', 'support', 'yet'], tags=[4]),\n",
       " TaggedDocument(words=['like', 'product', 'last', 'now', 'gone', 'dark', 'unrespons', 'tri', 'unplug', 'plug', 'back', 'ala', 'seem', 'dead'], tags=[5]),\n",
       " TaggedDocument(words=['receiv', 'alexa', 'yesterday', 'excit', 'begin', 'use', 'music', 'app', ''], tags=[6]),\n",
       " TaggedDocument(words=['think', 'put', 'hour', 'tri', 'make', 'work'], tags=[7]),\n",
       " TaggedDocument(words=['will', 'tri', 'get', 'help', 'may', 'send', 'back', '', 'sorri', 'say'], tags=[8]),\n",
       " TaggedDocument(words=['forgotten', 'life', 'alexa', 'like', 'love', 'everi', 'morn', 'wake', 'listen', 'flash', 'news', 'brief', 'chang', 'life', 'better', 'excit', 'see', 'futur', 'develop', 'hold', 'product'], tags=[9])]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.shuffle(Doc2VecTrainID)\n",
    "\n",
    "trainDoc = [documents[id] for id in Doc2VecTrainID]\n",
    "Labels = df.loc[:,'Sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "model_DM = Doc2Vec(size=400, window=8, min_count=1, sample=1e-4, negative=5, workers=cores,  dm=1, dm_concat=1 )\n",
    "model_DBOW = Doc2Vec(size=400, window=8, min_count=1, sample=1e-4, negative=5, workers=cores, dm=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_DM.build_vocab(trainDoc)\n",
    "model_DBOW.build_vocab(trainDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for it in range(0,10):\n",
    "    random.shuffle(Doc2VecTrainID)\n",
    "    trainDoc = [documents[id] for id in Doc2VecTrainID]\n",
    "    model_DM.train(trainDoc,total_examples=model_DM.corpus_count,epochs=model_DM.iter)\n",
    "    model_DBOW.train(trainDoc,total_examples=model_DBOW.corpus_count,epochs=model_DBOW.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sheer', 0.2054240107536316),\n",
       " ('elsewher', 0.17939051985740662),\n",
       " ('involv', 0.1777307391166687),\n",
       " ('disast', 0.16461707651615143),\n",
       " ('predefin', 0.1643693447113037),\n",
       " ('headway', 0.1566038727760315),\n",
       " ('freeway', 0.15547911822795868),\n",
       " ('credit', 0.1547764390707016),\n",
       " ('plethora', 0.15466900169849396),\n",
       " ('regard', 0.15037207305431366)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DBOW predicts a random group of words in a paragraph given only its paragraph vector \n",
    "\n",
    "model_DBOW.similar_by_word(\"music\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amazonmus', 0.7000535726547241),\n",
       " ('aerosmith', 0.6887083649635315),\n",
       " ('attenu', 0.6389185190200806),\n",
       " ('iheartradio', 0.6302682757377625),\n",
       " ('goof', 0.6256952285766602),\n",
       " ('catalog', 0.625339925289154),\n",
       " ('lf', 0.6242313981056213),\n",
       " ('pandora', 0.6158062815666199),\n",
       " ('spotifi', 0.613024115562439),\n",
       " ('beyonc', 0.6058138012886047)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DM attempts to predict a word given its previous words and a paragraph vector. \n",
    "# Even though the context window moves across the text, the paragraph vector does not (hence distributed memory)\n",
    "# and allows for some word-order to be captured\n",
    "\n",
    "model_DM.similar_by_word(\"music\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fuller', 0.6294357180595398),\n",
       " ('altitud', 0.5691038370132446),\n",
       " ('speed', 0.5684019923210144),\n",
       " ('qualiti', 0.5675342082977295),\n",
       " ('adequ', 0.5570660829544067)]"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_DM.most_similar(positive=['biggest','small'], negative=['big'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_DBOW.wv.save_word2vec_format('trained.word2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import statsmodels.api as sm\n",
    "\n",
    "random.seed(45906)\n",
    "newindex = random.sample(range(0,TotalNum),TotalNum)\n",
    "testID = newindex[-TestNum:]\n",
    "trainID = newindex[:-TestNum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_targets_LR, train_regressors_LR = zip(*[(Labels[id], list(model_DM.docvecs[id])+list(model_DBOW.docvecs[id])) for id in trainID])\n",
    "train_regressors_LR = sm.add_constant(train_regressors_LR)\n",
    "#predictor = LogisticRegression(multi_class='multinomial',solver='lbfgs')\n",
    "predictor = LogisticRegression()\n",
    "predictor.fit(train_regressors_LR,train_targets_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accus=[]\n",
    "accu=0\n",
    "test_regressors_LR = [list(model_DM.docvecs[id])+list(model_DBOW.docvecs[id]) for id in testID]\n",
    "test_regressors_LR = sm.add_constant(test_regressors_LR)\n",
    "test_predictions_LR = predictor.predict(test_regressors_LR)\n",
    "for i in range(0,TestNum):\n",
    "    if test_predictions_LR[i]==df.loc[testID[i],u'Sentiments']:\n",
    "        accu=accu+1\n",
    "accus=accus+[1.0*accu/TestNum]\n",
    "confusionM = confusion_matrix(test_predictions_LR,(df.loc[testID,u'Sentiments']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'N': 284, 'P': 2021})"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(elem[0] for elem in (df.loc[testID,u'Sentiments']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   4,   10],\n",
       "       [ 255, 2036]])"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8850325379609545]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accus_train =[]\n",
    "accu=0\n",
    "train_predictions_LR = predictor.predict(train_regressors_LR)\n",
    "for i in range(0,len(train_targets_LR)):\n",
    "    if train_predictions_LR[i]==train_targets_LR[i]:\n",
    "        accu=accu+1\n",
    "accus_train =accus_train+[1.0*accu/len(train_targets_LR)]\n",
    "confusionM_Train = confusion_matrix(train_predictions_LR,train_targets_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'N': 1043, 'P': 8176})"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(elem[0] for elem in train_targets_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  17,   40],\n",
       "       [1026, 8136]])"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionM_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8843692374444083]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accus_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import statsmodels.api as sm\n",
    "\n",
    "random.seed(5705)\n",
    "newindex = random.sample(range(0,TotalNum),TotalNum)\n",
    "testID = newindex[-TestNum:]\n",
    "trainID = newindex[:-TestNum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_targets_SVM, train_regressors_SVM = zip(*[(Labels[id], list(model_DM.docvecs[id])+list(model_DBOW.docvecs[id])) for id in trainID])\n",
    "train_regressors_SVM = sm.add_constant(train_regressors_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC()\n",
    "#clf = svm.SVC(gamma=0.001, C=100)\n",
    "clf = svm.SVC(C=1.0, kernel='linear', gamma='auto')\n",
    "svmmodel = clf.fit(train_regressors_SVM,train_targets_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accus=[]\n",
    "accu=0\n",
    "test_regressors_SVM = [list(model_DM.docvecs[id])+list(model_DBOW.docvecs[id]) for id in testID]\n",
    "test_regressors_SVM = sm.add_constant(test_regressors_SVM)\n",
    "test_predictions_SVM = svmmodel.predict(test_regressors_SVM)\n",
    "for i in range(0,TestNum):\n",
    "    if test_predictions_SVM[i]==df.loc[testID[i],u'Sentiments']:\n",
    "        accu=accu+1\n",
    "accus=accus+[1.0*accu/TestNum]\n",
    "confusionM = confusion_matrix(test_predictions_SVM,(df.loc[testID,u'Sentiments']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'N': 284, 'P': 2021})"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(elem[0] for elem in (df.loc[testID,u'Sentiments']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0],\n",
       "       [ 284, 2021]])"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8767895878524946]"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'N': 1018, 'P': 8201})"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(elem[0] for elem in train_targets_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accus_train =[]\n",
    "accu=0\n",
    "train_predictions_SVM = svmmodel.predict(train_regressors_SVM)\n",
    "for i in range(0,len(train_targets_SVM)):\n",
    "    if train_predictions_SVM[i]==train_targets_SVM[i]:\n",
    "        accu=accu+1\n",
    "accus_train =accus_train+[1.0*accu/len(train_targets_SVM)]\n",
    "confusionM_Train = confusion_matrix(train_predictions_SVM,train_targets_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0],\n",
       "       [1018, 8201]])"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionM_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8895758759084499]"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accus_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import statsmodels.api as sm\n",
    "\n",
    "random.seed(49526)\n",
    "newindex = random.sample(range(0,TotalNum),TotalNum)\n",
    "testID = newindex[-TestNum:]\n",
    "trainID = newindex[:-TestNum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_targets_SGD, train_regressors_SGD = zip(*[(Labels[id], list(model_DM.docvecs[id])+list(model_DBOW.docvecs[id])) for id in trainID])\n",
    "train_regressors_SGD = sm.add_constant(train_regressors_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = SGDClassifier(loss='log', penalty='l1')\n",
    "modelSGD = lr.fit(train_regressors_SGD, train_targets_SGD)\n",
    "\n",
    "#print 'Test Accuracy: %.2f'%lr.score(test_vecs, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_regressors_SGD = [list(model_DM.docvecs[id])+list(model_DBOW.docvecs[id]) for id in testID]\n",
    "test_regressors_SGD = sm.add_constant(test_regressors_SGD)\n",
    "test_predictions_SGD = modelSGD.predict(test_regressors_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accus=[]\n",
    "accu=0\n",
    "test_predictions_SGD = modelSGD.predict(test_regressors_SGD)\n",
    "for i in range(0,TGD\n",
    "        accu=accu+1\n",
    "accus=accus+[1.0*accu/TestNum]\n",
    "confusionM = confusion_matrix(test_predictions_SGD,(df.loc[testID,u'Sentiments']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   7,   22],\n",
       "       [ 258, 2018]])"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8785249457700651]"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accus_train =[]\n",
    "accu=0\n",
    "train_predictions_SGD = svmmodel.predict(train_regressors_SGD)\n",
    "for i in range(0,len(train_targets_SGD)):\n",
    "    if train_predictions_SGD[i]==train_targets_SGD[i]:\n",
    "        accu=accu+1\n",
    "accus_train =accus_train+[1.0*accu/len(train_targets_SGD)]\n",
    "confusionM_Trai = confusion_matrix(train_predictions_SGD,train_targets_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0],\n",
       "       [1037, 8182]])"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionM_Trai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8875149148497667]"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accus_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Belief Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_DBN, dataset_DBN = zip(*[(Labels[id], list(model_DM.docvecs[id])+list(model_DBOW.docvecs[id])) for id in range(TotalNum)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = open('val', \"wb\")#Open the file\n",
    "pickle.dump(target_DBN, w,protocol=2)#Dump the dictionary bok, the first parameter into the file object w.\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = open('data', \"wb\")#Open the file\n",
    "pickle.dump(dataset_DBN, w,protocol=2)#Dump the dictionary bok, the first parameter into the file object w.\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Due to compatability issues we will pass these data into a Python Virtual Environment with Python 2.7.3 and binaries installed\n",
    "#### Below code is for the code completeness purpose and work only with Oython 2.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#python -m idlelib.idle\n",
    "import pickle\n",
    "\n",
    "## loading the data\n",
    "w1=open(\"C:\\\\Users\\\\lalit\\\\Documents\\\\val\", 'rb') #Open the file\n",
    "targets =pickle.load(w1) #Assign the recreated object to bok\t\n",
    "print \"Loaded the targets\"\n",
    "\n",
    "w2=open(\"C:\\\\Users\\\\lalit\\\\Documents\\\\data\", 'rb') #Open the file\n",
    "dataset = pickle.load(w2) #Assign the recreated object to bok\n",
    "print \"Loaded the dataset\"\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from nolearn.dbn import DBN\n",
    "import numpy as np\n",
    "#import cv2\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(dataset, targets, test_size = 0.30)\n",
    "X = np.array(trainX)\n",
    "text_X = np.array(testX)\n",
    "\n",
    "# train the Deep Belief Network with number of columns of all reviews (800) in our case (len(trainx[1]), 400 hidden units, 2 output units \n",
    "dbn = DBN(\n",
    "\t[X.shape[1], 400, 2],\n",
    "\tlearn_rates = 0.01,\n",
    "\tlearn_rate_decays = 0.2,\n",
    "\tepochs = 12,\n",
    "\tverbose = 1)\n",
    "dbn.fit(X, trainY)\n",
    "\n",
    "# compute the predictions for the test data and show a classification\n",
    "# report\n",
    "preds = dbn.predict(text_X)\n",
    "print classification_report(testY, preds)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
