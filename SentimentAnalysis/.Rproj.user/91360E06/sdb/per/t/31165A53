{
    "collab_server" : "",
    "contents" : "\n\nlibrary(dplyr)\nlibrary(rvest)\n\n## Loading the page to get the review page\n#url <- \"https://www.amazon.com/All-New-Amazon-Echo-Dot-Add-Alexa-To-Any-Room/dp/B01DFKC2SO/ref=redir_mobile_desktop?_encoding=UTF8&ref_=ods_gw_ha_d_3pack\"\nurl <- \"https://www.amazon.com/Amazon-Echo-Bluetooth-Speaker-with-WiFi-Alexa/dp/B00X4WHP5E/ref=s9u_simh_gw_i2?_encoding=UTF8&fpl=fresh&pd_rd_i=B00X4WHP5E&pd_rd_r=F5K20DTJEQHV3WG9XZP0&pd_rd_w=piZZ2&pd_rd_wg=kS3ou&pf_rd_m=ATVPDKIKX0DER&pf_rd_s=&pf_rd_r=W6VQZ4FB0Q96E1NGPKVR&pf_rd_t=36701&pf_rd_p=781f4767-b4d4-466b-8c26-2639359664eb&pf_rd_i=desktop\"\n\nmain.page <- read_html(x = url)\nreview.page <- main.page %>% html_nodes(xpath = '//*[@id=\"revF\"]/div/a') %>% xml_attr(\"href\")\nif(length(review.page) == 0) {\n  review.page <- main.page %>% html_nodes(xpath = '//*[@id=\"reviews-medley-footer\"]/div[1]/a') %>% xml_attr(\"href\")\n  review.page <- paste(\"https://www.amazon.com\",review.page,sep=\"\")\n}\n\n\n## Scraping the review page and writing it to the Review folder\n\nXPATH_REVIEW_SECTION_2 = '//div[@data-hook=\"review\"]'\nXPATH_REVIEW_SECTION_3 = '//span[@data-hook=\"review-body\"]//text()'\n\npage = 1000\np = 1\nfor (i in 1:page){\n  newpage <- paste(review.page,\"&pageNumber=\",i,sep = \"\")\n  readreviewpage <- read_html(x=newpage)\n  reviews <- readreviewpage %>% html_nodes(xpath = XPATH_REVIEW_SECTION_2) %>% \n    html_nodes(xpath = XPATH_REVIEW_SECTION_3) %>% html_text()  \n  \n    if(length(reviews) > 0){\n        for (j in 1:length(reviews)){\n          r <- as.character(reviews[j])\n          filename <- paste(\"reviews/Review\",p,\".txt\",sep = \"\")\n          write(r,file = filename)\n          p = p+1\n        }\n    }\n}\n\n\nlibrary(\"tm\")\nlibrary(\"SnowballC\")\n\n# # Loading the corpus\n#\n# reviewcorpus  <-Corpus(DirSource(\"reviews/\"))\n# summary(reviewcorpus)\n# reviewcorpus <- tm_map(reviewcorpus, removeNumbers)\n# reviewcorpus <- tm_map(reviewcorpus, removePunctuation)\n# reviewcorpus <- tm_map(reviewcorpus , stripWhitespace)\n# reviewcorpus <- tm_map(reviewcorpus, tolower)\n# reviewcorpus <- tm_map(reviewcorpus, removeWords, stopwords(\"english\")) # this stopword file is at C:\\Users\\[username]\\Documents\\R\\win-library\\2.13\\tm\\stopwords\n# reviewcorpus <- tm_map(reviewcorpus, stemDocument, language = \"english\")\n# adtm <-DocumentTermMatrix(reviewcorpus, control=list(wordLengths=c(3,Inf)))\n\n###\n\n\npos <- scan('positive-words.txt', what='character', comment.char=';')\nneg <- scan('negative-words.txt', what='character', comment.char=';')\npos.words <- c(pos, 'upgrade')\nneg.words <- c(neg, 'wtf', 'wait', 'waiting', 'epicfail')\n\n## Loading the corpus\nrequire(quanteda)\n\nreviewsInput <- quanteda::textfile(\"reviews/*.txt\")\nstr(reviewsInput)\nmyCorpus <- corpus(reviewsInput)\n\n## checking a review from the corpus\ntexts(myCorpus)[1]\n\n## making a dictionary of positive and negative words\nmyDict <- dictionary(list(positive = pos.words,negative = neg.words))\n\n## Quanteda will create Document Frequency Matrix by function dfm(). This function\n## essentially does this by series of operation including tokenizing, lowercasing, indexing\nreviews.sent <- dfm(myCorpus, stem = TRUE, removePunct = TRUE,dictionary = myDict,toLower = TRUE,removeNumbers = TRUE)\nreviews.sent\n\n###\nrequire(tidytext)\ntidy(reviews.sent)\n\n## Making a dataframe\nsentiment.df <- as.data.frame(as.matrix(reviews.sent))\nsentiment.df$document <- rownames(sentiment.df)\n\n## Adding all the reviews\nsentiment.df$Review <- NULL\nfor(i in 1:length(texts(myCorpus))){\n  sentiment.df[i,\"Review\"] <- texts(myCorpus)[i]\n}\n\n## Removing reviews which does not have positive or negative count\nsentiment.df <- sentiment.df[which(sentiment.df$posit != 0 | sentiment.df$negat != 0),]\n\n## labelling the document\nlibrary(dplyr)\nsentiment.df <- sentiment.df %>% mutate(label = if_else(posit>negat,\"Positive\",\"Negative\"))\n\n\n## Visualizing individual reviews sentiment\nlibrary(reshape2)\ndat_l <- melt(sentiment.df[,1:3], id.vars = c(\"document\"))\nlibrary(ggplot2)\np <- ggplot(data = dat_l, aes(x = document, y = value, group = variable, fill = variable))\np <- p + geom_bar(stat = \"identity\", width = 0.5, position = \"dodge\")\np <- p + theme_bw()\np <- p + theme(axis.text.x = element_text(angle = 90))\npng(filename=\"reviews/ReviewSentiment.png\")\nplot(p)\ndev.off()\n\n\n## computing and visualizing overall sentiment\n\noverall.sentiment <- data.frame(Positive = sum(sentiment.df$posit)/nrow(sentiment.df),\n                                Negative = sum(sentiment.df$negat/nrow(sentiment.df)),\n                                Review = \"Overall Review\")\nwrite.csv(overall.sentiment,\"reviews/OverallSentiment.csv\")\n\ndat_l2 <- melt(overall.sentiment, id.vars = c(\"Review\"))\np2 <- ggplot(data = dat_l2, aes(x = Review, y = value, group = variable, fill = variable))\np2 <- p2 + geom_bar(stat = \"identity\", width = 0.5, position = \"dodge\")\np2 <- p2 + theme_bw()\npng(filename=\"reviews/OverallSentiment.png\")\nplot(p2)\ndev.off()\n\n\n# Saving the file\nsentiment.df <- select(sentiment.df,Review,label)\nwrite.csv(sentiment.df,\"reviews/ReviewSentiment.csv\")\n\n\n# Saving the file\nsentiment.df_2 <- select(sentiment.df[1:3000,],Review,label)\nwrite.csv(sentiment.df_2,\"reviews/ReviewSentiment_2.csv\")\n\n",
    "created" : 1491091487668.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3553477440",
    "id" : "31165A53",
    "lastKnownWriteTime" : 1492573490,
    "last_content_update" : 1492573490542,
    "path" : "C:/Users/lalit/Dropbox/NEU_Curriculum/SEM5-Spring2017/BigData-Analytics/Final_Project/SentimentAnalysis/SentimentAnalysisScript.R",
    "project_path" : "SentimentAnalysisScript.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}